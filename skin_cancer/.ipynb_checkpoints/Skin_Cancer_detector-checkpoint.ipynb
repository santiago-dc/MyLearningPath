{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skin Cancer Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el siguiente notebook se expone el desarrollo de una CNN para clasificar fotografías de lunares en función de si son cancerígenas o no. El dataset está compuesto por fotografías en formato \".jpg\" separadas en carpetas según si pertenecen al set de entrenamiento o de test y según si son benignas o malignas. El dataset parece complicado puesto que las fotografías han sido tomadas desde distintos ángulos, con distinta luz y algunas imágenes se ven peor debido a que el paciente tenia vello en la zona del lunar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils.np_utils import to_categorical\n",
    "np.random.seed(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ETL process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "benign_train_folder = 'data/train/benign'\n",
    "malignant_train_folder = 'data/train/malignant'\n",
    "\n",
    "benign_test_folder = 'data/test/benign'\n",
    "malignant_test_folder = 'data/test/malignant'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función para leer todas las imágenes de una carpeta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read(folder_path):\n",
    "    data_path = os.path.join(folder_path,'*jpg')\n",
    "    folder = glob.glob(data_path)\n",
    "    matrix = []\n",
    "    for f in folder:\n",
    "        img = np.asarray(Image.open(f).convert(\"RGB\"))\n",
    "        matrix.append(img)\n",
    "    matrix = np.asarray(matrix)\n",
    "    return matrix\n",
    "\n",
    "#Create data\n",
    "X_benign_train = read(benign_train_folder)\n",
    "X_malignant_train = read(malignant_train_folder)\n",
    "X_benign_test = read(benign_test_folder)\n",
    "X_malignant_test = read(malignant_test_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos las etiquetas para cada set de datos; 0 para los benignos y 1 para los malignos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_benign_train = np.zeros(X_benign_train.shape[0])\n",
    "Y_malignant_train = np.ones(X_malignant_train.shape[0])\n",
    "Y_benign_test = np.zeros(X_benign_test.shape[0])\n",
    "Y_malignant_test = np.ones(X_malignant_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenamos los set de datos y los barajamos, la red funcionaría peor si los datos de entrenamiento estuvieran ordenados en función la salida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.concatenate((X_benign_train, X_malignant_train), axis = 0)\n",
    "Y_train = np.concatenate((Y_benign_train, Y_malignant_train), axis = 0)\n",
    "s = np.arange(X_train.shape[0])\n",
    "np.random.shuffle(s)\n",
    "X_train = X_train[s]\n",
    "Y_train = Y_train[s]\n",
    "\n",
    "X_test = np.concatenate((X_benign_test, X_malignant_test), axis = 0)\n",
    "Y_test = np.concatenate((Y_benign_test, Y_malignant_test), axis = 0)\n",
    "s = np.arange(X_test.shape[0])\n",
    "np.random.shuffle(s)\n",
    "X_test = X_test[s]\n",
    "Y_test = Y_test[s]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizaión y transformación de las salidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Turn labels into one hot encoding (ya veremos si esto hace falta o si lo dejo)\n",
    "Y_train = to_categorical(Y_train, num_classes= 2)\n",
    "Y_test = to_categorical(Y_test, num_classes= 2)\n",
    "\n",
    "# Normalization\n",
    "X_train = X_train/255.\n",
    "X_test = X_test/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, AveragePooling2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se implementa un modelo con 3 capas convolucionales y 3 capas de Maxpooling que vuelcan los resultados en una capa fully connected conectada con una capa de 30 neuronas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential() #Test Acc:  0.760606050491333\n",
    "#add model layers\n",
    "model.add(Conv2D(128, kernel_size=11, activation='relu', input_shape=(224,224,3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=2, padding='same', data_format=None))\n",
    "\n",
    "model.add(Conv2D(128, kernel_size=11, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=2, padding='same', data_format=None))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=11, activation='relu'))\n",
    "mode.add(MaxPooling2D(pool_size=(2, 2), strides=2, padding='same', data_format=None))\n",
    "\n",
    "mode.add(Flatten())\n",
    "mode.add(Dense(30, activation='relu'))\n",
    "mode.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compilamos con optimizer=adam y loss=categorical_crossentropy. Despues entrenamos el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train, validation_data=(X_test, Y_test), batch_size=16, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último, evaluamos dicho modelo con los datos de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model2.evaluate(X_test, Y_test, batch_size=16)\n",
    "print('Test Acc: ', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2637/2637 [==============================] - 1944s 737ms/step - loss: 0.6709 - accuracy: 0.7323\n",
      "Epoch 2/5\n",
      "2637/2637 [==============================] - 2061s 782ms/step - loss: 0.4218 - accuracy: 0.7967\n",
      "Epoch 3/5\n",
      "2637/2637 [==============================] - 1948s 739ms/step - loss: 0.4040 - accuracy: 0.8093\n",
      "Epoch 4/5\n",
      "2637/2637 [==============================] - 1860s 705ms/step - loss: 0.4073 - accuracy: 0.8058\n",
      "Epoch 5/5\n",
      " 592/2637 [=====>........................] - ETA: 27:45 - loss: 0.3902 - accuracy: 0.8091"
     ]
    }
   ],
   "source": [
    "from keras.applications.resnet50 import ResNet50\n",
    "model = ResNet50(include_top=True,\n",
    "                 weights= None,\n",
    "                 input_tensor=None,\n",
    "                 input_shape=[224,224,3],\n",
    "                 pooling='avg',\n",
    "                 classes=2)\n",
    "\n",
    "model.compile(#optimizer = Adam(lr) ,\n",
    "              optimizer='adam',\n",
    "              loss = \"binary_crossentropy\", \n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(X_train, Y_train, #validation_split=0.2,\n",
    "                    epochs= 5, batch_size= 16, #verbose=2, \n",
    "                    #callbacks=[learning_rate_reduction]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test, Y_test, batch_size=16)\n",
    "print('Test Acc: ', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(layers.Convolution2D(32, (3, 3), activation='relu', input_shape=(64, 64, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.BatchNormalization())\n",
    "\n",
    "model.add(layers.Convolution2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.BatchNormalization())\n",
    "\n",
    "model.add(layers.Convolution2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.BatchNormalization())\n",
    "\n",
    "model.add(layers.Convolution2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.BatchNormalization())\n",
    "    \n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('base': conda)",
   "language": "python",
   "name": "python37464bitbaseconda8f9e7eec01e94c97b8bc3bc94eea3dbf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
