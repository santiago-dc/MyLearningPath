{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skin Cancer Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el siguiente notebook se expone el desarrollo de una CNN para clasificar fotografías de lunares en función de si son cancerígenas o no. El dataset está compuesto por fotografías en formato \".jpg\" separadas en carpetas según si pertenecen al set de entrenamiento o de test y según si son benignas o malignas. El dataset parece complicado puesto que las fotografías han sido tomadas desde distintos ángulos, con distinta luz y algunas imágenes se ven peor debido a que el paciente tenia vello en la zona del lunar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils.np_utils import to_categorical\n",
    "np.random.seed(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ETL process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "benign_train_folder = 'data/train/benign'\n",
    "malignant_train_folder = 'data/train/malignant'\n",
    "\n",
    "benign_test_folder = 'data/test/benign'\n",
    "malignant_test_folder = 'data/test/malignant'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función para leer todas las imágenes de una carpeta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read(folder_path):\n",
    "    data_path = os.path.join(folder_path,'*jpg')\n",
    "    folder = glob.glob(data_path)\n",
    "    matrix = []\n",
    "    for f in folder:\n",
    "        img = np.asarray(Image.open(f).convert(\"RGB\"))\n",
    "        matrix.append(img)\n",
    "    matrix = np.asarray(matrix)\n",
    "    return matrix\n",
    "\n",
    "#Create data\n",
    "X_benign_train = read(benign_train_folder)\n",
    "X_malignant_train = read(malignant_train_folder)\n",
    "X_benign_test = read(benign_test_folder)\n",
    "X_malignant_test = read(malignant_test_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos las etiquetas para cada set de datos; 0 para los benignos y 1 para los malignos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_benign_train = np.zeros(X_benign_train.shape[0])\n",
    "Y_malignant_train = np.ones(X_malignant_train.shape[0])\n",
    "Y_benign_test = np.zeros(X_benign_test.shape[0])\n",
    "Y_malignant_test = np.ones(X_malignant_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenamos los set de datos y los barajamos, la red funcionaría peor si los datos de entrenamiento estuvieran ordenados en función la salida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.concatenate((X_benign_train, X_malignant_train), axis = 0)\n",
    "Y_train = np.concatenate((Y_benign_train, Y_malignant_train), axis = 0)\n",
    "s = np.arange(X_train.shape[0])\n",
    "np.random.shuffle(s)\n",
    "X_train = X_train[s]\n",
    "Y_train = Y_train[s]\n",
    "\n",
    "X_test = np.concatenate((X_benign_test, X_malignant_test), axis = 0)\n",
    "Y_test = np.concatenate((Y_benign_test, Y_malignant_test), axis = 0)\n",
    "s = np.arange(X_test.shape[0])\n",
    "np.random.shuffle(s)\n",
    "X_test = X_test[s]\n",
    "Y_test = Y_test[s]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizaión y transformación de las salidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Turn labels into one hot encoding (ya veremos si esto hace falta o si lo dejo)\n",
    "Y_train = to_categorical(Y_train, num_classes= 2)\n",
    "Y_test = to_categorical(Y_test, num_classes= 2)\n",
    "\n",
    "# Normalization\n",
    "X_train = X_train/255.\n",
    "X_test = X_test/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, AveragePooling2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se implementa un modelo con 3 capas convolucionales y 3 capas de Maxpooling que vuelcan los resultados en una capa fully connected conectada con una capa de 30 neuronas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential() #Test Acc:  0.760606050491333\n",
    "#add model layers\n",
    "model.add(Conv2D(128, kernel_size=7, activation='relu', input_shape=(224,224,3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=2, padding='same', data_format=None))\n",
    "\n",
    "model.add(Conv2D(128, kernel_size=5, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=2, padding='same', data_format=None))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=2, padding='same', data_format=None))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(30, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compilamos con optimizer=adam y loss=categorical_crossentropy. Despues entrenamos el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train, batch_size=32, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último, evaluamos dicho modelo con los datos de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test, Y_test, batch_size=16)\n",
    "print('Test Acc: ', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Otro modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2637/2637 [==============================] - 1944s 737ms/step - loss: 0.6709 - accuracy: 0.7323\n",
      "Epoch 2/5\n",
      "2637/2637 [==============================] - 2061s 782ms/step - loss: 0.4218 - accuracy: 0.7967\n",
      "Epoch 3/5\n",
      "2637/2637 [==============================] - 1948s 739ms/step - loss: 0.4040 - accuracy: 0.8093\n",
      "Epoch 4/5\n",
      "2637/2637 [==============================] - 1860s 705ms/step - loss: 0.4073 - accuracy: 0.8058\n",
      "Epoch 5/5\n",
      "2637/2637 [==============================] - 2048s 777ms/step - loss: 0.3839 - accuracy: 0.8111\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1b8a8ea3cc8>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.applications.resnet50 import ResNet50\n",
    "model = ResNet50(include_top=True,\n",
    "                 weights= None,\n",
    "                 input_tensor=None,\n",
    "                 input_shape=[224,224,3],\n",
    "                 pooling='avg',\n",
    "                 classes=2)\n",
    "\n",
    "model.compile(#optimizer = Adam(lr) ,\n",
    "              optimizer='adam',\n",
    "              loss = \"binary_crossentropy\", \n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(X_train, Y_train, #validation_split=0.2,\n",
    "                    epochs= 5, batch_size= 16, #verbose=2, \n",
    "                    #callbacks=[learning_rate_reduction]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "660/660 [==============================] - 160s 242ms/step\n",
      "Test Acc:  0.7515151500701904\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test, Y_test, batch_size=16)\n",
    "print('Test Acc: ', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Otro modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, AveragePooling2D, BatchNormalization, Dropout\n",
    "model = Sequential()\n",
    "model.add(Conv2D(128, kernel_size=7, activation='relu', input_shape=(224,224,3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=2, padding='same', data_format=None))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(128, kernel_size=5, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=2, padding='same', data_format=None))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=2, padding='same', data_format=None))\n",
    "model.add(BatchNormalization())\n",
    "    \n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(30, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "2637/2637 [==============================] - 811s 308ms/step - loss: 1.3937 - accuracy: 0.6716\n",
      "Epoch 2/3\n",
      "2637/2637 [==============================] - 858s 325ms/step - loss: 0.7556 - accuracy: 0.7110\n",
      "Epoch 3/3\n",
      "2637/2637 [==============================] - 1250s 474ms/step - loss: 0.8008 - accuracy: 0.7725\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x10e75e8c848>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train, batch_size=64, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "660/660 [==============================] - 72s 109ms/step\n",
      "Test Acc:  0.5515151619911194\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test, Y_test, batch_size=16)\n",
    "print('Test Acc: ', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Otro modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, AveragePooling2D, BatchNormalization, Dropout\n",
    "model = Sequential()\n",
    "model.add(Conv2D(128, kernel_size=7, activation='relu', input_shape=(224,224,3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=2, padding='same', data_format=None))\n",
    "model.add(BatchNormalization())\n",
    "#model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(128, kernel_size=5, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=2, padding='same', data_format=None))\n",
    "model.add(BatchNormalization())\n",
    "#model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=2, padding='same', data_format=None))\n",
    "model.add(BatchNormalization())\n",
    "#model.add(Dropout(0.25))\n",
    "    \n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(125, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(30, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "2637/2637 [==============================] - 738s 280ms/step - loss: 2.2206 - accuracy: 0.6162\n",
      "Epoch 2/3\n",
      "2637/2637 [==============================] - 734s 278ms/step - loss: 0.7776 - accuracy: 0.6553\n",
      "Epoch 3/3\n",
      "2637/2637 [==============================] - 737s 280ms/step - loss: 0.5659 - accuracy: 0.7448\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x2222cb544c8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train, batch_size=16, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "660/660 [==============================] - 56s 84ms/step\n",
      "Test Acc:  0.7696969509124756\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test, Y_test, batch_size=16)\n",
    "print('Test Acc: ', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## El mismo pero 5 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, AveragePooling2D, BatchNormalization, Dropout\n",
    "model = Sequential()\n",
    "model.add(Conv2D(128, kernel_size=7, activation='relu', input_shape=(224,224,3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=2, padding='same', data_format=None))\n",
    "model.add(BatchNormalization())\n",
    "#model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(128, kernel_size=5, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=2, padding='same', data_format=None))\n",
    "model.add(BatchNormalization())\n",
    "#model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=2, padding='same', data_format=None))\n",
    "model.add(BatchNormalization())\n",
    "#model.add(Dropout(0.25))\n",
    "    \n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(125, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(30, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2637/2637 [==============================] - 735s 279ms/step - loss: 3.1937 - accuracy: 0.6447\n",
      "Epoch 2/5\n",
      "2637/2637 [==============================] - 734s 278ms/step - loss: 0.7880 - accuracy: 0.7270\n",
      "Epoch 3/5\n",
      "2637/2637 [==============================] - 734s 278ms/step - loss: 0.5560 - accuracy: 0.7497\n",
      "Epoch 4/5\n",
      "2637/2637 [==============================] - 735s 279ms/step - loss: 0.4681 - accuracy: 0.7812\n",
      "Epoch 5/5\n",
      "2637/2637 [==============================] - 731s 277ms/step - loss: 0.4642 - accuracy: 0.7740\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x2222d409688>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train, batch_size=16, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "660/660 [==============================] - 55s 84ms/step\n",
      "Test Acc:  0.7863636612892151\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test, Y_test, batch_size=16)\n",
    "print('Test Acc: ', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Por dios que sea el bueno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, AveragePooling2D, BatchNormalization, Dropout\n",
    "model = Sequential()\n",
    "model.add(Conv2D(128, kernel_size=7, activation='relu', input_shape=(224,224,3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=2, padding='same', data_format=None))\n",
    "model.add(BatchNormalization())\n",
    "#model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(128, kernel_size=5, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=2, padding='same', data_format=None))\n",
    "model.add(BatchNormalization())\n",
    "#model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=2, padding='same', data_format=None))\n",
    "model.add(BatchNormalization())\n",
    "#model.add(Dropout(0.25))\n",
    "    \n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(125, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(30, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "2637/2637 [==============================] - 753s 286ms/step - loss: 1.2705 - accuracy: 0.6595\n",
      "Epoch 2/8\n",
      "2637/2637 [==============================] - 748s 284ms/step - loss: 0.5437 - accuracy: 0.7509\n",
      "Epoch 3/8\n",
      "2637/2637 [==============================] - 744s 282ms/step - loss: 0.4906 - accuracy: 0.7607\n",
      "Epoch 4/8\n",
      "2637/2637 [==============================] - 740s 280ms/step - loss: 0.4365 - accuracy: 0.7842\n",
      "Epoch 5/8\n",
      "2637/2637 [==============================] - 735s 279ms/step - loss: 0.4357 - accuracy: 0.7895\n",
      "Epoch 6/8\n",
      "2637/2637 [==============================] - 735s 279ms/step - loss: 0.4534 - accuracy: 0.7782\n",
      "Epoch 7/8\n",
      "2637/2637 [==============================] - 733s 278ms/step - loss: 0.4015 - accuracy: 0.7945\n",
      "Epoch 8/8\n",
      "2637/2637 [==============================] - 735s 279ms/step - loss: 0.3914 - accuracy: 0.8077\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x2222e06e308>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train, batch_size=16, epochs=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "660/660 [==============================] - 57s 86ms/step\n",
      "Test Acc:  0.8196969628334045\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test, Y_test, batch_size=16)\n",
    "print('Test Acc: ', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit",
   "language": "python",
   "name": "python37664bitafcaf6bb83bd42b38a1a3d733de9b838"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
