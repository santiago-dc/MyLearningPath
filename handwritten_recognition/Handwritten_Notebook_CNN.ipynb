{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handwritten numbers Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extraer datos. Las imágenes son de 28*28 píxeles, por lo tanto el csv tiene 784 columnas más 1 indicando la salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract():\n",
    "    df_train = pd.read_csv('data/mnist_train.csv', delimiter = ',').to_numpy()\n",
    "    df_test = pd.read_csv('data/mnist_test.csv', delimiter = ',').to_numpy()\n",
    "    df = pd.DataFrame(np.concatenate((df_train,df_test)))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformar output a array de 10 y separar de las inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(df): \n",
    "    y_raw = df.iloc[:, 0].to_numpy()\n",
    "    x = df.drop(df.columns[0], axis='columns').to_numpy()\n",
    "    y = []\n",
    "    for i in range(0,y_raw.shape[0]):\n",
    "        row=np.zeros(10)\n",
    "        row[y_raw[i]]=1\n",
    "        y.append(row)\n",
    "    y=np.array(y)\n",
    "    y.reshape(y.shape[0],10)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos los dataset de entrenamiento y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = extract()\n",
    "x_train,y_train = transform(df.iloc[0:60000])\n",
    "#x_val,y_val = transform(df.iloc[50000:60000])\n",
    "x_test,y_test = transform(df.iloc[60000:70000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(60000,28,28,1)\n",
    "x_test = x_test.reshape(9998,28,28,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creación de la Red Neuronal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la red neuronal vamoas a implementar una arquitectura de (784,512,256,128,10), con funciones de activación ReLu en todas las capas menos en la última, en la cual utilizaremos la funcion softmax (https://www.quora.com/Why-is-it-better-to-use-Softmax-function-than-sigmoid-function).<br> Para cada capa se utilizará la funcion Dense, la cual tiene los siguientes parámetros por defecto:\n",
    "- activation=None,\n",
    "- use_bias=True,\n",
    "- kernel_initializer='glorot_uniform',\n",
    "- bias_initializer='zeros',\n",
    "- kernel_regularizer=None,\n",
    "- bias_regularizer=None,\n",
    "- activity_regularizer=None,\n",
    "- kernel_constraint=None,\n",
    "- bias_constraint=None\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "#add model layers\n",
    "model.add(Conv2D(64, kernel_size=3, activation='relu', input_shape=(28,28,1)))\n",
    "model.add(Conv2D(32, kernel_size=3, activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a crear y entrenar el modelo, 50 epochs serán suficientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 9998 samples\n",
      "Epoch 1/3\n",
      "60000/60000 [==============================] - 58s 973us/step - loss: 0.0197 - accuracy: 0.9938 - val_loss: 0.0811 - val_accuracy: 0.9795\n",
      "Epoch 2/3\n",
      "60000/60000 [==============================] - 61s 1ms/step - loss: 0.0075 - accuracy: 0.9977 - val_loss: 0.1083 - val_accuracy: 0.9790\n",
      "Epoch 3/3\n",
      "60000/60000 [==============================] - 61s 1ms/step - loss: 0.0051 - accuracy: 0.9983 - val_loss: 0.0978 - val_accuracy: 0.9821\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x187860b2208>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])#learning_rate=0.001\n",
    "model.fit(x_train, y_train,validation_data=(x_test, y_test), batch_size=200, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluamos el modelo con el acierto de los datos de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9998/9998 [==============================] - 2s 211us/step\n",
      "Test Acc:  0.9820964336395264\n"
     ]
    }
   ],
   "source": [
    "tes_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print('Test Acc: ', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
